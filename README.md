# Multimodal-RAG-QA

This project aims to integrate multiple data modalities to enhance the accuracy and contextuality of responses in AI-driven QA systems.

## Project Overview
This system uses a novel approach by combining text and visual information to process user queries more effectively. By leveraging advances in AI and machine learning, we provide richer, more accurate answers that integrate seamlessly into various applications.

## Features
- **Multimodal Data Integration:** Utilizes both text and image data for comprehensive query understanding.
- **Advanced RAG Techniques:** Employs state-of-the-art Retriever-Augmented Generation models to enhance answer quality.
- **Wide Application Range:** From educational tools to customer service enhancements, this system is versatile.

## Getting Started
To get started with this project, clone this repository and follow the setup instructions below.

### Installation
```bash
git clone https://github.com/himanshu-skid19/Multimodal-RAG-QA.git
cd Multimodal-RAG-QA
pip install -r requirements.txt
```

#### Setup the Qdrant Server
1. Make sure you have Docker installed and running
2. Run the following:
```bash
docker pull qdrant/qdrant
docker run -d --name qdrant_server -p 6333:6333 qdrant/qdrant
```

### Team Members:

1. Himanshu Singhal - [@himanshu-skid19](https://github.com/himanshu-skid19)
2. Anushka Gupta - [@anushkacodez](https://github.com/anushkacodez)
3. Atul Jha - [@Atul-04](https://github.com/Atul-04)
4. Parth Agarwal - [@Parth-Agarwal216](https://github.com/Parth-Agarwal216)
